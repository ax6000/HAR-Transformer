{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VhQSb7PdZznG"
      },
      "source": [
        "# Sequence-to-sequence activity recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2y0GYTdc-nY",
        "outputId": "8a4c97ee-752b-4ef3-a83d-e6da46c5f019"
      },
      "outputs": [],
      "source": [
        "# !pip3 install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOaWIFSBM-",
        "outputId": "475bc447-6414-46af-c5ec-49526e2808f8"
      },
      "outputs": [],
      "source": [
        "# !pip3 install git+https://github.com/tensorflow/addons.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VSncNSHtZznI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bsa\\Anaconda3\\envs\\shl2023\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Add, Dense, Dropout, MultiHeadAttention, LayerNormalization, Layer, Normalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, Callback, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model,Sequence\n",
        "from tensorflow_addons.optimizers import AdamW\n",
        "from wandb.keras import WandbCallback\n",
        "from sklearn.model_selection import train_test_split \n",
        "# from sklern.metric.preprocessing import StandardScaler\n",
        "import math\n",
        "import wandb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# パス（相対パスで書くこと。他の環境でも動作させるため。）\n",
        "OUTPUT_DIR = '../output/model/transformer/'\n",
        "MODEL_OUT = '0606'\n",
        "# TRAINING_PATH = '../data/every_5s_normalized/train/'\n",
        "# VAL_PATH = '../data/every_5s_normalized/validate/'\n",
        "# TEST_PATH = '../data/every_5s_normalized/test/'\n",
        "# POS = 'Hand'\n",
        "# FILENAME_ACC = \"Acc_every_5s.npy\"\n",
        "# FILENAME_GYR = \"Gyr_every_5s.npy\"\n",
        "# FILENAME_MAG = \"Mag_every_5s.npy\"\n",
        "# FILENAME_LABEL = 'Label_every_5s.npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_kdFgpMxZznJ"
      },
      "source": [
        "## Init logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6DnpqLPZznK",
        "outputId": "078f5861-e753-4525-fe92-0516ac23f007"
      },
      "outputs": [],
      "source": [
        "# wandb.login()\n",
        "\n",
        "sweep_config = {\n",
        "  'method': 'grid',\n",
        "  'metric': {\n",
        "    'goal': 'maximize',\n",
        "    'name': 'val_accuracy'\n",
        "  },\n",
        "  'parameters': {\n",
        "      'epochs': {\n",
        "        'value': 50\n",
        "      },\n",
        "      'num_layers': {\n",
        "        'value': 3\n",
        "      },\n",
        "      'embed_layer_size': {\n",
        "        'value': 128\n",
        "      },\n",
        "      'fc_layer_size': {\n",
        "        'value': 256\n",
        "      },\n",
        "      'num_heads': {\n",
        "        'value': 6\n",
        "      },\n",
        "      'dropout': {\n",
        "        'value': 0.1\n",
        "      },\n",
        "      'attention_dropout': {\n",
        "        'value': 0.1\n",
        "      },\n",
        "      'optimizer': {\n",
        "        'value': 'adam'\n",
        "      },\n",
        "      'amsgrad': {\n",
        "        'value': False\n",
        "      },\n",
        "      'label_smoothing': {\n",
        "        'value': 0.1\n",
        "      },\n",
        "      'learning_rate': {\n",
        "        'value': 1e-3\n",
        "      },\n",
        "      #'weight_decay': {\n",
        "      #    'values': [2.5e-4, 1e-4, 5e-5, 1e-5]\n",
        "      #},\n",
        "      'warmup_steps': {\n",
        "        'value': 10\n",
        "      },\n",
        "      'batch_size': {\n",
        "        'value': 64\n",
        "      },\n",
        "      'global_clipnorm': {\n",
        "        'value': 3.0\n",
        "      },\n",
        "    }\n",
        "}\n",
        "\n",
        "# sweep_id = wandb.sweep(sweep_config, project=\"HAR-Transformer\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mGp0L3_ZznL"
      },
      "source": [
        "## Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0lFGhNtyZznL"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(Layer):\n",
        "    def __init__(self, units, dropout_rate, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "        self.projection = Dense(units, kernel_initializer=TruncatedNormal(stddev=0.02))\n",
        "\n",
        "        self.dropout = Dropout(rate=dropout_rate)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(PositionalEmbedding, self).build(input_shape)\n",
        "\n",
        "        self.position = self.add_weight(\n",
        "            name=\"position\",\n",
        "            shape=(1, input_shape[1], self.units),\n",
        "            initializer=TruncatedNormal(stddev=0.02),\n",
        "            trainable=True,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.projection(inputs)\n",
        "        x = x + self.position\n",
        "\n",
        "        return self.dropout(x, training=training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PIwd6GlIZznM"
      },
      "outputs": [],
      "source": [
        "class Encoder(Layer):\n",
        "    def __init__(\n",
        "        self, embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate, **kwargs\n",
        "    ):\n",
        "        super(Encoder, self).__init__(**kwargs)\n",
        "\n",
        "        self.mha = MultiHeadAttention(\n",
        "            num_heads=num_heads,\n",
        "            key_dim=embed_dim,\n",
        "            dropout=attention_dropout_rate,\n",
        "            kernel_initializer=TruncatedNormal(stddev=0.02),\n",
        "        )\n",
        "\n",
        "        self.dense_0 = Dense(\n",
        "            units=mlp_dim,\n",
        "            activation=\"gelu\",\n",
        "            kernel_initializer=TruncatedNormal(stddev=0.02),\n",
        "        )\n",
        "        self.dense_1 = Dense(\n",
        "            units=embed_dim, kernel_initializer=TruncatedNormal(stddev=0.02)\n",
        "        )\n",
        "\n",
        "        self.dropout_0 = Dropout(rate=dropout_rate)\n",
        "        self.dropout_1 = Dropout(rate=dropout_rate)\n",
        "\n",
        "        self.norm_0 = LayerNormalization(epsilon=1e-5)\n",
        "        self.norm_1 = LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "        self.add_0 = Add()\n",
        "        self.add_1 = Add()\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        # Attention block\n",
        "        x = self.norm_0(inputs)\n",
        "        x = self.mha(\n",
        "            query=x,\n",
        "            value=x,\n",
        "            key=x,\n",
        "            training=training,\n",
        "        )\n",
        "        x = self.dropout_0(x, training=training)\n",
        "        x = self.add_0([x, inputs])\n",
        "\n",
        "        # MLP block\n",
        "        y = self.norm_1(x)\n",
        "        y = self.dense_0(y)\n",
        "        y = self.dense_1(y)\n",
        "        y = self.dropout_1(y, training=training)\n",
        "\n",
        "        return self.add_1([x, y])\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YRQTRP60ZznN"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UYEKK7pYZznN"
      },
      "outputs": [],
      "source": [
        "class Transformer(Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_layers,\n",
        "        embed_dim,\n",
        "        mlp_dim,\n",
        "        num_heads,\n",
        "        num_classes,\n",
        "        dropout_rate,\n",
        "        attention_dropout_rate,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super(Transformer, self).__init__(**kwargs)\n",
        "\n",
        "        # Input (normalization of RAW measurements)\n",
        "        self.input_norm = Normalization()\n",
        "\n",
        "        # Input\n",
        "        self.pos_embs = PositionalEmbedding(embed_dim, dropout_rate)\n",
        "\n",
        "        # Encoder\n",
        "        self.e_layers = [\n",
        "            Encoder(embed_dim, mlp_dim, num_heads, dropout_rate, attention_dropout_rate)\n",
        "            for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        # Output\n",
        "        self.norm = LayerNormalization(epsilon=1e-5)\n",
        "        self.final_layer = Dense(num_classes, kernel_initializer=\"zeros\")\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        x = self.input_norm(inputs)\n",
        "        x = self.pos_embs(x, training=training)\n",
        "\n",
        "        for layer in self.e_layers:\n",
        "            x = layer(x, training=training)\n",
        "\n",
        "        x = self.norm(x)\n",
        "        x = self.final_layer(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j42cze_qiAIb"
      },
      "source": [
        "## Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NK6QapYViAIb"
      },
      "outputs": [],
      "source": [
        "def smoothed_sparse_categorical_crossentropy(label_smoothing: float = 0.0):\n",
        "    def loss_fn(y_true, y_pred):\n",
        "        num_classes = tf.shape(y_pred)[-1]\n",
        "        y_true = tf.one_hot(y_true, num_classes)\n",
        "\n",
        "        loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True, label_smoothing=label_smoothing)\n",
        "        return tf.reduce_mean(loss)\n",
        "\n",
        "    return loss_fn"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PxmZ1ZWBAgLX"
      },
      "source": [
        "## LR scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GEtbF3TdAjDU"
      },
      "outputs": [],
      "source": [
        "def cosine_schedule(base_lr, total_steps, warmup_steps):\n",
        "    def step_fn(epoch):\n",
        "        lr = base_lr\n",
        "        epoch += 1\n",
        "\n",
        "        progress = (epoch - warmup_steps) / float(total_steps - warmup_steps)\n",
        "        progress = tf.clip_by_value(progress, 0.0, 1.0)\n",
        "        \n",
        "        lr = lr * 0.5 * (1.0 + tf.cos(math.pi * progress))\n",
        "\n",
        "        if warmup_steps:\n",
        "            lr = lr * tf.minimum(1.0, epoch / warmup_steps)\n",
        "\n",
        "        return lr\n",
        "\n",
        "    return step_fn\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MBlu9AxBHG09"
      },
      "outputs": [],
      "source": [
        "class PrintLR(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        wandb.log({\"lr\": self.model.optimizer.lr.numpy()}, commit=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7dIynjZAZznP"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data(type):\n",
        "    TRAINING_PATH = '../data/every_5s/train/'\n",
        "    VAL_PATH = '../data/every_5s/validate/'\n",
        "    TEST_PATH = '../data/every_5s/test/'\n",
        "    POS = 'Hand'\n",
        "    FILENAME_ACC = \"Acc_every_5s.npy\"\n",
        "    FILENAME_GYR = \"Gyr_every_5s.npy\"\n",
        "    FILENAME_MAG = \"Mag_every_5s.npy\"\n",
        "    FILENAME_LABEL = 'Label_every_5s.npy'\n",
        "    TYPE = ['train','test','validate']\n",
        "    if type == 'train':\n",
        "        dir = TRAINING_PATH\n",
        "    elif type == 'validate':\n",
        "        dir = VAL_PATH\n",
        "    elif type == 'test':\n",
        "        dir = TEST_PATH\n",
        "    else:\n",
        "        print('type is not valid.')\n",
        "        return\n",
        "    acc = np.load(os.path.join(dir,POS,FILENAME_ACC))[:,:,1:]\n",
        "    gyr = np.load(os.path.join(dir,POS,FILENAME_GYR))[:,:,1:]\n",
        "    mag = np.load(os.path.join(dir,POS,FILENAME_MAG))[:,:,1:]\n",
        "    \n",
        "    y = np.load(os.path.join(dir,FILENAME_LABEL))[:,:,1:].squeeze().astype('uint8')-1 if type != 'test' else None\n",
        "    X = np.concatenate([acc,gyr,mag],axis=2).astype('float32')\n",
        "    # print(X.shape,y.shape)\n",
        "    return X,y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GkimkgOZznP",
        "outputId": "c43e079b-f8b2-4d51-f9b0-a5339a3c9b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(190037, 500, 9) (190037, 500)\n",
            "(21650, 500, 9) (21650, 500)\n"
          ]
        }
      ],
      "source": [
        "CLASS_LABELS = np.array(\n",
        "    ['Still', 'Walking', 'Run', 'Bike', 'Car', 'Bus', 'Train', 'Subway']\n",
        ")\n",
        "\n",
        "# load dataset\n",
        "X_train,y_train = load_data('train')\n",
        "X_val,y_val = load_data('validate')\n",
        "print(X_train.shape, y_train.shape)\n",
        "# print(X_test.shape, y_test.shape)\n",
        "print(X_val.shape, y_val.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "RSXjG7qHZznQ",
        "outputId": "c83fae89-3e09-4f05-eb7f-6c4b6ab76db4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11863500 11608000  3789500 11692000 15759000 13993000 15476500 10837000]\n",
            "<class 'numpy.uint8'>\n",
            "[2127000 1896000   59500  964000 1541000  644000 1425500 2168000]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApUAAAK3CAYAAADUNbSaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAxOAAAMTgF/d4wjAABATElEQVR4nO3deVTVdf7H8ReL6YyQJqKiiKgorom74pKQ5VZYZmmuNCpopSZlOllONaPZ1OBoziSpWSpqbjmUjZV75gbuS5o6IqASLilRLiz394c/7sSISn0ufK/d5+MczoHLx+ub71F48t2um81mswkAAAAw4G71AAAAALjzEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwJhTReWoUaMUGBgoNzc37dmz57br9+/fr5CQEPtbYGCgKlSoUPyDAgAAoABPqwf4ud69e+vFF19U+/bti7S+cePGBeLz2WeflZubWzFNBwAAgJtxqj2VHTt2lL+//w2PJyYmKjw8XC1atFDTpk21dOnSG9ZcuXJF8fHxGjJkSEmMCgAAgJ9xqj2Vhbl48aKioqL02Wefyc/PT+fOnVOzZs0UGhqqatWq2detWLFCtWrVUkhIiHXDAgAAuCinj8otW7boP//5j7p161bg8SNHjhSIyjlz5rCXEgAAwCJOH5U2m00NGzbUli1bbrrmxIkT2rZtm5YvX16CkwEAACCfU51TWZjQ0FCdOHFCa9assT+2Z88eXbt2zf7x+++/r0cffVTly5e3YEIAAAC42Ww2m9VD5IuOjtaqVauUnp4uHx8feXt769ixY9q1a5deeOEFnT9/XtnZ2QoICNDKlStVpkwZ5eXlqUaNGpo3b57CwsKs/hIAAABcklNFJQAAAO5MTn/4GwAAAM7PaS7UKV26tHx9fa0eAwAAADdx9uxZXb16tdDPOU1U+vr6Ki0tzeoxAAAAcBOFvUhNPg5/AwAAwBhRCQAAAGNEJQAAAIw5zTmVt5KXlyfufFQy3Nzc5O7O7xoAAOCXceqovHbtmlJSUpSdnW31KC6lVKlSCggI0F133WX1KAAA4A7h1FGZkpIib29v+fj4yM3NzepxXILNZtP58+eVkpKioKAgq8cBAAB3CKeNyry8PGVnZ8vHx0eenk475m+Sj4+PLly4oLy8PA6FAwCAInHaYsg/h5I9lCUvf5tzHisAACgqp41KAAAA3DnuuOPKgeNXFcvzJk/pcds1ISEhkq5fQHTkyBE1btxYkhQcHKyPPvqoSH9PQkKC1q9fr6lTp/7qWQEAAJzNHReVVtqzZ48kKTk5WSEhIfaPfy4nJ+eW54BGREQoIiKimCYEAACwBoe/HSAwMFDjxo1Tq1atNHjwYKWnpyssLEzNmzdXw4YN9eyzzyovL0+S9MEHH+iRRx6RJG3YsEGNGjXS008/rSZNmqhhw4ZKSkqy8CsBAAD4dYhKBzl//ry2b9+u+Ph4lS9fXp988ol27typffv2KTk5WUuWLCn0zx0+fFiDBw/W3r17NXLkSE2YMKGEJwcAADBHVDpIZGSk/arpvLw8jRs3Tk2aNFHTpk2VlJRU6KFySQoKClLr1q0lSW3bttXx48dLamQAAACH4ZxKB/Hy8rK/Hxsbq4yMDG3fvl1lypRRTEyMrly5UuifK1OmjP19Dw8P5eTkFPusAAAAjsaeymLw/fffq0qVKipTpozS09O1dOlSq0cCAAAoVkXaUzlq1CglJCTo5MmT2r17t/3WOv9r//79GjlypL777jtJ0qRJk9SrVy+HDSsV7dY/Vhs9erR69+6thg0bqmrVqurcubPVIwEAABQrN1sRXjZl06ZNqlWrltq3b6+VK1cWGpU//fSTGjVqpHnz5ql9+/bKzc3VhQsX5OvrW6RB/P39lZaWZv84NzdX3377rerWrSsPD4+if0UwxrYHAACF+d9e+7ki7ans2LHjbdcsXLhQbdq0Ufv27SVdPz+wqEEJAACAO5vDzqk8dOiQSpcurYceekghISEaNGiQzp49e9P1sbGx8vf3t79lZWU5ahQAAACUMIdFZU5OjtasWaO4uDjt3r1b1apV04gRI266PiYmRmlpafa3n189DQAAgDuLw6IyICBAYWFhqlatmtzc3DRgwABt27bNUU8PAAAAJ+awqHziiSeUmJiozMxMSdJnn32mJk2aOOrpAQAA4MSKFJXR0dH2q326dOmioKAgSdLQoUOVkJAg6fqeypdeekmhoaG69957tW7dOs2cObP4JgcAAIDTKNIthUpCkW8p9Gq54hng1UvF87x3IG4pBAAACnOrWwrxijq/QPfu3TVjxowbHm/SpIlWrFhR6J/54IMP9Mgjj0iSkpKS1KdPn0LXZWVl2V87/FYuXryoKVOmFHhs6NChWr9+/W3/LAAAQHEhKn+BIUOGaO7cuQUeS0pK0pkzZ/Twww/f9s+3aNFCH330kdEMhUXl7NmzFRYWZvS8AAAAJojKXyAiIkKpqanat2+f/bH3339fERERevDBB9W8eXM1bNhQzz77rPLy8m748xs2bCjwakRxcXGqU6eOmjZtqqlTpxZY279/f7Vo0UL33nuvevToofT0dEnS8OHD9cMPPygkJEQtWrSQJHXq1EkrV66UJGVkZKhXr15q3LixGjVqpLi4OPtzBgYGauLEiWrbtq1q1qypv/zlL47aNAAAwMUV6RV1cF2pUqU0cOBAvf/++/r73/+uK1euaNGiRdqyZYuqV68uLy8v5ebmqmfPnlqyZIn69u170+c6cOCA/vSnP2n37t3y8/PTSy+9VODzf//73+2vSDRlyhS9+uqrmjlzpmbOnKmQkBDt2bOn0OcdOXKkgoODtWLFCmVkZKh58+Zq0qSJ2rRpI+n6ns6tW7fq3Llzql27tp566ilVq1bNMRsIQJEFjl9l9QglInlKD6tHAFBC2FP5Cw0ZMkTx8fG6du2aVqxYofr166tGjRoaN26cmjRpoqZNmyopKemm0Zdv3bp16tatm/z8/CTphhvFL1y4UC1atFCjRo00e/bs2z5fvjVr1ig6OlqSVKlSJfXq1Utr1qyxf75fv36SpIoVK6pWrVo6ceJEEb9yAACAmyMqf6EGDRooKChIn3zyid5//30NGTJEsbGxysjI0Pbt27Vv3z7169dPV65c+UXP+/OLdDZv3qzp06frs88+04EDBxQbG/uLn6+w55WkMmXK2N/38PBQTk7Or3peAACAnyMqf4UhQ4Zo8uTJ2rFjh/r06aPvv/9eVapUUZkyZZSenq6lS5fe9jnCw8O1evVq+7mSP7+n5/fffy9vb2/5+Pjo2rVrBc6LvPvuu3X58mVdu3at0Oft3LmzZs2aJUk6e/asVqxYoQceeMDkywUAALitO++cSie4n2SfPn303HPPqU+fPvLy8tLo0aPVu3dvNWzYUFWrVlXnzp1v+xyNGjXSq6++qg4dOsjLy0u9evWyf65r165asGCBgoOD5ePjo86dO+vUqVOSpAoVKmjQoEG699575eXlpaSkpALPO336dI0YMUKNGzeWzWbThAkT1Lp1a8duAAAAgP9x5938HMWObQ8UPy7UAXAn4ubnAAAAKFZEJQAAAIw5bVTmX7XsJEfnXUr+Ni/Ky0YCAABITnyhjru7u0qVKqXz58/Lx8eHwCkhNptN58+fV6lSpeTu7rS/cwAAACfjtFEpSQEBAUpJSdGFCxesHsWllCpVSgEBAVaPAQC4CS70gjNy6qi86667FBQUpLy8PA6DlxA3Nzf2UAIAgF/MqaMyH5EDAADg3Kg1AAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCtSVI4aNUqBgYFyc3PTnj17brnWZrMpPDxc5cuXd8B4AAAAuBMUKSp79+6tzZs3q0aNGrddO3XqVNWuXdt4MAAAANw5ihSVHTt2lL+//23XHTx4UCtXrtT48eONBwMAAMCdw9NRT5Sdna1hw4Zpzpw58vDwuO362NhYxcbG2j/Oyspy1CgAgDtc4PhVVo9QIpKn9LB6BMBhHHahzmuvvaZevXqpfv36RVofExOjtLQ0+5uXl5ejRgEAAEAJc9ieyo0bNyolJUUzZsxQTk6OMjMzFRgYqMTERPn6+jrqrwEAAIATclhUfvXVV/b3k5OTFRISouTkZEc9PQAAAJxYkQ5/R0dHy9/fX2lpaerSpYuCgoIkSUOHDlVCQkKxDggAAADnV6Q9lXFxcYU+Pnv27EIfDwwM1MWLF3/1UAAAALiz8Io6AAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMBYkaJy1KhRCgwMlJubm/bs2VPomnXr1qlVq1Zq0KCBGjZsqBdffFF5eXmOnBUAAABOqkhR2bt3b23evFk1atS46Zp77rlHixcv1qFDh7Rz505t2bJF8+bNc9igAAAAcF6eRVnUsWPH265p2rSp/f0yZcooJCREycnJv3owAAAA3DmK5ZzK9PR0LVu2TA899NBN18TGxsrf39/+lpWVVRyjAAAAoAQ4PCozMzP18MMP68UXX1SLFi1uui4mJkZpaWn2Ny8vL0ePAgAAgBLi0Kj84Ycf1LVrV/Xs2VMxMTGOfGoAAAA4MYdFZVZWlrp27aquXbvq5ZdfdtTTAgAA4A5QpKiMjo6Wv7+/0tLS1KVLFwUFBUmShg4dqoSEBEnStGnTtGPHDq1YsUIhISEKCQnRpEmTim9yAAAAOI0iXf0dFxdX6OOzZ8+2vz9hwgRNmDDBMVOVgMDxq6weoUQkT+lh9QgAAMAF8Io6AAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBWpKu/AeCX4O4KAOB62FMJAAAAY0QlAAAAjHH4G4Xi8CUAAPgl2FMJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwJin1QMAAAA4WuD4VVaPUOySp/SweoQC2FMJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMFakqBw1apQCAwPl5uamPXv23HTdnDlzVKdOHdWuXVvDhg1Tdna2o+YEAACAEytSVPbu3VubN29WjRo1brrmxIkTeuWVV/TVV1/p2LFj+u677/Tee+85bFAAAAA4ryJFZceOHeXv73/LNcuWLVNERISqVKkiNzc3DR8+XIsWLXLIkAAAAHBuDjunMiUlpcCezMDAQKWkpNx0fWxsrPz9/e1vWVlZjhoFAAAAJcyyC3ViYmKUlpZmf/Py8rJqFAAAABhyWFQGBATo5MmT9o+Tk5MVEBDgqKcHAACAE3NYVD722GNKSEhQenq6bDabZs6cqb59+zrq6QEAAODEihSV0dHR8vf3V1pamrp06aKgoCBJ0tChQ5WQkCBJqlWrll577TW1a9dOQUFB8vX1VXR0dPFNDgAAAKfhWZRFcXFxhT4+e/bsAh8PGzZMw4YNM58KAAAAdxReUQcAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCtyVB49elShoaGqW7euWrZsqYMHD96wJi8vTzExMWrQoIHuvfdehYWF6dixYw4dGAAAAM6nyFEZHR2tqKgoffvttxo3bpwiIyNvWJOQkKCvv/5ae/fu1b59+3T//ffrpZdecuS8AAAAcEJFisqMjAwlJSVpwIABkqTHHntMqampN+yFdHNz09WrV3XlyhXZbDZlZmbK39/f8VMDAADAqXgWZVFqaqr8/Pzk6Xl9uZubmwICApSSkqKgoCD7uocffljr169XlSpV5O3trWrVqmnjxo2FPmdsbKxiY2PtH2dlZZl8HQAAALCQQy/USUpK0oEDB3Tq1CmdPn1a999/v4YPH17o2piYGKWlpdnfvLy8HDkKAAAASlCRorJ69eo6c+aMcnJyJEk2m00pKSkKCAgosG7evHkKDw9X+fLl5e7ursGDB2v9+vWOnxoAAABOpUhRWalSJTVr1kwLFiyQJC1fvlz+/v4FDn1LUq1atbRu3Tpdu3ZNkvTpp5+qUaNGDh4ZAAAAzqZI51RKUlxcnCIjIzV58mTdfffdmjt3riRp6NChioiIUEREhJ555hl98803atKkiUqVKqUqVapo5syZxTY8AAAAnEORozI4OFhbt2694fHZs2fb3y9durRmzZrlmMkAAABwx+AVdQAAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgrMhRefToUYWGhqpu3bpq2bKlDh48WOi6/fv3q1OnTqpfv77q16+vFStWOGxYAAAAOCfPoi6Mjo5WVFSUIiMjtWzZMkVGRioxMbHAmp9++kk9e/bUvHnz1L59e+Xm5urChQsOHxoAAADOpUh7KjMyMpSUlKQBAwZIkh577DGlpqbq2LFjBdYtXLhQbdq0Ufv27SVJHh4e8vX1dfDIAAAAcDZFisrU1FT5+fnJ0/P6jk03NzcFBAQoJSWlwLpDhw6pdOnSeuihhxQSEqJBgwbp7NmzhT5nbGys/P397W9ZWVmGXwoAAACs4tALdXJycrRmzRrFxcVp9+7dqlatmkaMGFHo2piYGKWlpdnfvLy8HDkKAAAASlCRorJ69eo6c+aMcnJyJEk2m00pKSkKCAgosC4gIEBhYWGqVq2a3NzcNGDAAG3bts3xUwMAAMCpFCkqK1WqpGbNmmnBggWSpOXLl8vf319BQUEF1j3xxBNKTExUZmamJOmzzz5TkyZNHDwyAAAAnE2Rr/6Oi4tTZGSkJk+erLvvvltz586VJA0dOlQRERGKiIhQQECAXnrpJYWGhsrd3V3VqlXTe++9V2zDAwAAwDkUOSqDg4O1devWGx6fPXt2gY8HDhyogQMHmk8GAACAOwavqAMAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0WOyqNHjyo0NFR169ZVy5YtdfDgwZuutdlsCg8PV/ny5R0xIwAAAJxckaMyOjpaUVFR+vbbbzVu3DhFRkbedO3UqVNVu3ZtR8wHAACAO0CRojIjI0NJSUkaMGCAJOmxxx5Tamqqjh07dsPagwcPauXKlRo/frxjJwUAAIDTKlJUpqamys/PT56enpIkNzc3BQQEKCUlpcC67OxsDRs2THFxcfLw8Ljlc8bGxsrf39/+lpWV9Su/BAAAAFjNoRfqvPbaa+rVq5fq169/27UxMTFKS0uzv3l5eTlyFAAAAJQgz6Isql69us6cOaOcnBx5enrKZrMpJSVFAQEBBdZt3LhRKSkpmjFjhnJycpSZmanAwEAlJibK19e3WL4AAAAAWK9IeyorVaqkZs2aacGCBZKk5cuXy9/fX0FBQQXWffXVVzp58qSSk5O1efNm3X333UpOTiYoAQAAfuOKfPg7Li5OcXFxqlu3rqZMmaK5c+dKkoYOHaqEhIRiGxAAAADOr0iHvyUpODhYW7duveHx2bNnF7o+MDBQFy9e/NWDAQAA4M7BK+oAAADAGFEJAAAAY0U+/A3gvwLHr7J6hBKRPKWH1SMAAO4Q7KkEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgzNPqAQAAABwtuUw/q0coAZesHqAAl41K1/jHJjnbPzgAAPDbxOFvAAAAGCtyVB49elShoaGqW7euWrZsqYMHD96wZt26dWrVqpUaNGighg0b6sUXX1ReXp5DBwYAAIDzKXJURkdHKyoqSt9++63GjRunyMjIG9bcc889Wrx4sQ4dOqSdO3dqy5YtmjdvniPnBQAAgBMqUlRmZGQoKSlJAwYMkCQ99thjSk1N1bFjxwqsa9q0qWrVqiVJKlOmjEJCQpScnOzYiQEAAOB0ihSVqamp8vPzk6fn9et63NzcFBAQoJSUlJv+mfT0dC1btkwPPfRQoZ+PjY2Vv7+//S0rK+tXjA8AAABnUCwX6mRmZurhhx/Wiy++qBYtWhS6JiYmRmlpafY3Ly+v4hgFAAAAJaBIUVm9enWdOXNGOTk5kiSbzaaUlBQFBATcsPaHH35Q165d1bNnT8XExDh2WgAAADilIkVlpUqV1KxZMy1YsECStHz5cvn7+ysoKKjAuqysLHXt2lVdu3bVyy+/7PhpAQAA4JSKfPPzuLg4RUZGavLkybr77rs1d+5cSdLQoUMVERGhiIgITZs2TTt27NCPP/6oFStWSJIef/xxTZgwoXimR7Hh5vAAAOCXKHJUBgcHa+vWrTc8Pnv2bPv7EyZMICABAABcEK+oAwAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMFbk1/4GADhOcpl+Vo9QQi5ZPQCAEsKeSgAAABgjKgEAAGCMqAQAAIAxzqkEAOAOwzm5cEbsqQQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAMaISAAAAxohKAAAAGCMqAQAAYIyoBAAAgDGiEgAAAMaISgAAABgjKgEAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgzNPqAQD89iSX6Wf1CCXkktUDAIDTYE8lAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGK/9DQBwOrx+PHDnYU8lAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRCUAAACMEZUAAAAwRlQCAADAGFEJAAAAY0QlAAAAjBGVAAAAMEZUAgAAwBhRCQAAAGNEJQAAAIwRlQAAADBGVAIAAMAYUQkAAABjRY7Ko0ePKjQ0VHXr1lXLli118ODBQtfNmTNHderUUe3atTVs2DBlZ2c7bFgAAAA4J8+iLoyOjlZUVJQiIyO1bNkyRUZGKjExscCaEydO6JVXXtGuXbtUuXJl9ezZU++9956eeeYZhw8OWCm5TD+rRyghl6weAABwhyjSnsqMjAwlJSVpwIABkqTHHntMqampOnbsWIF1y5YtU0REhKpUqSI3NzcNHz5cixYtcvzUAAAAcCpF2lOZmpoqPz8/eXpeX+7m5qaAgAClpKQoKCjIvi4lJUU1atSwfxwYGKiUlJRCnzM2NlaxsbH2j9PT0+Xv7/+rvohfx7sE/67rsrKy5OXlVbJ/6exfu03ZPrfG9rk1ts/tsY1uje1za2yf2yvZbXTnbZ9f5+zZszf9XJEPfztaTEyMYmJirPrrLeHv76+0tDSrx3BabJ9bY/vcGtvn9thGt8b2uTW2z62xfYp4+Lt69eo6c+aMcnJyJEk2m00pKSkKCAgosC4gIEAnT560f5ycnHzDGgAAAPz2FCkqK1WqpGbNmmnBggWSpOXLl8vf37/AoW/p+rmWCQkJSk9Pl81m08yZM9W3b1/HTw0AAACnUuRbCsXFxSkuLk5169bVlClTNHfuXEnS0KFDlZCQIEmqVauWXnvtNbVr105BQUHy9fVVdHR08Ux+B3K1w/2/FNvn1tg+t8b2uT220a2xfW6N7XNrbB/JzWaz2aweAgAAAHc2XlEHAAAAxohKAAAAGCMqAQAAYIyoLCF5eXlWjwAAAFBsiMoS4u5+fVPn5eWJa6MAAMBvDVFZzDIyMtSjRw8tWrRIly9flru7u9zc3CQRmEBx4KhAQbm5uZKkPXv2aN++fRZPgzvZlStXtG3bNl25csXqUe4IP/zwgyTX+p5EVBaz7OxsBQcHa+7cuWrXrp2GDRumtWvXSlKBwITsgX3hwgVNnz79hteNJ8ALYnsULv+oAK7L3x4TJ07U8ePHJf03NPHf/0f5AfBzrhQDN5O/DY4dO6Y+ffpowoQJuvfee9W3b1+tXr3a4umc14ULFzR58mRJrvU9yXW+UotUq1ZNsbGxWrJkif7yl7/od7/7nSZMmKD27dtr9OjRBV7WEtetX79ezz33nOrXr69OnTpp/vz5unTpkksGeP439B9//FGnT5/W1q1blZycLEkuuT0Kk7+Njh8/rj/+8Y967rnnbviFxJW5ubkpMzNTHh4eateunSTJw8NDNpuNaNJ/o3LSpElat26dJOnSpUuSXCsGbmfOnDny8fHRwoULFR8fr5o1a2rUqFF68MEHrR7NKWVmZmrTpk3q0aOHS30/4ubnxeg///mPxowZox49eqhLly6qUaOGJCk1NVVfffWVFi9erPHjxys0NNTiSZ3LyJEj1bZtW9WpU0dffPGF/vrXv8rLy0t9+/bVhAkTVKFCBatHLDF5eXlyd3fX8OHDlZiYqBo1aqhq1aqqVauWgoOD1aFDB919991Wj2m53NxctW7dWsOHD1d0dLQOHz4sPz8/HTt2TCEhIVaPZ7lNmzbpySeflK+vr8aPH68HHnhAPj4+Vo9lOZvNJjc3N509e1bh4eHavXu3Lly4oKioKG3fvl3Lli2zh7irGzt2rEaOHKmAgAD7LyPnz59XZmamateubfF0zikvL08TJkzQyZMnNXnyZAUGBtq/p/9WEZXF6OjRo5o/f75SUlKUkZGhgIAAde7cWZ07d1b58uWtHs+p5H9z37Vrl5588kkdOXLE/rlNmzbpvffeU1pamvr3769hw4ZZOGnJO3funDp16qQvv/xShw8f1q5du3TixAmdOnVKb7zxhurVq2f1iJbJ/wa9aNEibdy4Ua+++qr69u2rDRs26Pjx43rqqae0Zs0a3XXXXVaPaqkjR47o4MGD2rZtm06cOKGcnBz5+voqJiaGfz/u7po2bZqOHz+u6dOna+LEibp69aoaNGiggwcP6q9//avVY1om//vygQMHdN999+nBBx/UW2+9JX9/f6tHuyPk5eXp2rVrGjt2rE6ePKlZs2apcuXKVo9VrDytHuC3LDAwUOPHj9e5c+e0Z88e7dixQ4sWLdKCBQvk5+enMWPGqG7dulaP6RR+fii3fv36OnfunCpWrCjp+iGosmXLaurUqRo1apTLRGX+D7wdO3YoLCxMfn5+8vPzU1hYmM6cOaO9e/e6dBBI/z08uXfvXg0ePFgLFixQjx49JEkbN25U1apVXT4oJSk4OFjBwcGKiIjQsWPHtHPnTm3YsEGlS5e2ejRL5f/78fT0lKenp7p06aI2bdpo8uTJevfddws9z9KV5H9fLl++vMaOHavPP/9cPXr0UFBQkLp3767+/furdOnSnIrz//K/Z7/77rtKTU3VXXfdpcOHD6tq1ar68ssv1aFDB82ePVsdO3a0etRiw57KYrJ7927t3r1bgwcP1sGDB9W4cWPZbDYdPXpUSUlJWr9+vSZMmKCaNWtaPapTuXr1qgYPHqwjR46oW7duql27tv71r3+pd+/e8vT01FdffaV3333X6jFL1IQJE7Ry5UpFRUWpW7duqlmzpkqVKmX1WE5l//79Gj16tA4ePKjPP/9cISEhCg8P19ixY9WtWzerx7NE/g+4AwcO6NChQzpz5owCAwPVqlUr+fn56cqVKypTpozVYzqNF154QaVKldILL7wgHx8ftWrVSjNnzlSzZs2sHs0S586dU3x8vEaPHq3s7GyVKlVKubm5SkxM1Nq1a7VkyRK9/vrr6tmzp9WjOp13331XiYmJatmypcqWLatLly7p/vvvtx9tevvtt1W2bFmrxywWRGUxSUxMlI+Pj44fP66pU6eqcePGat68uUJDQ+Xv76+rV6+6/F6CW1myZIm2bNmir7/+Ws8884z69u1rP6eyZcuWVo9XYnJycjR37lzt3r1b3333nSpVqqR69eqpdu3a6tKli0vHZX40nTp1SpUrV9bChQu1ZMkS5ebm6uTJk3r44Yf15ptvWj2m5cLCwtSwYUN9/PHHatWqlWw2m4KCgjRixAiXPhcu/9/PJ598ogoVKhQ4d3LdunWKj4/XnDlzLJzQWgcOHNDZs2dVpUoVRUVFqXv37urSpYs9si9duiRvb+/f9PmBxaFy5cr68ssvde+991o9SrEgKovZzp07tXfvXh07dkynTp2Sh4eHypUrp5EjR6pWrVpWj+cU8r+5p6amavXq1apTp446depUYM3Fixf1xRdf6IknnrBmyBKWv00yMjLk4+MjDw8P7d27V+vXr9fXX3+tqlWratq0aVaPaan8870GDRqkcePGqWHDhlq7dq28vb3l5eWlBg0aWD2iZXJzc+Xh4aH169frH//4h5YtW6YmTZronXfe0dixY1W9enXNmTNH5cqVs3pUy/3pT3/S2rVrVa5cOYWGhqpPnz4KCgpSVlaWvLy8rB7PUjabTYcPH9bnn3+uI0eO6OTJk/Lx8VGzZs3Uv39/VapUyeoRncbPf44tXrxY1atXV+vWreXv72//5f/HH3/U66+//pv+ZZeoLAY5OTny9PTUli1btH37do0ZM0ZZWVk6cOCAdu/erQMHDmjSpElcrPMzly9fVrt27VS3bl2tWbNGubm56tu3r4YPH64mTZpYPZ5lhg0bpvLlyys0NFQtWrRQ9erVdfnyZZ07d07Vq1e3ejzLZWdn6/nnn1ebNm3Ur18/++OzZs1Sv379frOHmIoqKipK9913n65evar9+/dr6tSpSkhI0Jo1azR9+nSrx3MK6enpOn36tPbt26e1a9dq7969CgoKUnx8vH73u99ZPZ7TOH/+vPbv36+kpCRt2LBBr732mpo3b271WE7l8uXL6ty5s1q1aqVp06apSpUqCg0N1eOPP66IiAiX+PfEhTrFYNu2bfL09NS0adPsh2q9vLzUpk0bNWjQQN999x1B+f/y9zatWrVKgYGBWrx4saTr96qcNm2aOnTooO+//14eHh4WT1rycnNzFR4erm3btumDDz7QokWLVKdOHXXo0EFdunSxejxL7dy5U82bN1epUqXUp08fvffee+rSpYvWrl2rxYsXy9PT02Uu6Ppf+ffHCwoKUmRkpOrVq6d58+YpMzNTp06d0ocffqiHH37Y6jGdRpUqVVSlShXVr19fISEhevPNN9W2bVuXCICb+fmRktTUVKWkpKhGjRpq27atOnXqpP79+8vPz8/qMZ1G/pGBxYsXq3nz5oqJidHx48f1xhtvqFevXtq7d68ef/xxq8csEURlMfnDH/6gY8eO6Z577tHWrVtVu3ZtVapUSUOHDtVTTz2lOnXqWD2iU8iPyoyMDA0YMMD+eFhYmMLCwuyf/63f26swHh4eevLJJ/Xkk08qNTVV8+fP19SpU1WqVCl17drV6vEsk5OTo9GjR+vy5ctq3769RowYoYsXL2rw4MHy8/PTE0884dI3ZJ49e7YOHjyo559/3n4P3P79++vpp5/Ws88+q9OnT6tPnz4WT+kcnnvuOXXq1EkPPPCAypYtq5CQEJUtW1ZBQUFWj2ap/O+1zz33nPLy8pSUlKTGjRurcuXKaty4sR599FGLJ3Qu+Ts9PvvsM7300kuaOXOm2rZtq4YNG2rkyJEqV66c3N3d7fH5W0ZUOtiqVasUEhKixYsXa8aMGcrLy1P//v1Vu3ZttWnTRnv37tV9991n9ZhOw93dXRcuXNDzzz8vLy8vff/99xoyZIj98/m3qnC1oJSu743z9/eXr6+vqlevrpdeeknnzp1z+Zsxe3p6Kj4+Xjt37tSqVavUv39/HTlyRHXr1tV7772nqlWrWj2ipZYvX65Zs2bZzynNzc2Vr6+v+vbtq+PHj2vMmDEufYGXdH1PXEpKinJychQfH6/58+crMDBQ9erV04YNG/TOO+9YPaJl8n+RP3TokE6dOqWNGzeqbt26euSRRzR58mT95z//4YrvQuTl5enJJ59UzZo1lZeXJ19fX0nSBx98oL/97W+SXOPnGOdUOljTpk01ZswY9e/fXx4eHrp48aK+/PJLrV27VhUrVtSDDz74m75H1a/17bff6qOPPlJ8fLwuXLigNm3a6IUXXnDZbbVhwwaNHz9e7du3V/v27VWzZk1dvXpVw4YN0/bt2136VjDr1q1TWFiY/ReOb7/9Vlu2bNH69eu1YcMG9e7d2/5N3NUkJSUpOjpaO3fuvOFzeXl5euKJJzR58mSXvj/u/PnzdejQIVWtWlUDBw7Uzp07lZaWppSUFO3Zs0fdu3cv8Iutq8mPyrFjx8rPz0/16tXTokWLNH/+fCUkJOjf//63y93W7Vby9z6mpaXZbwq/ceNGde/eXc2aNZOXl5f+/e9/WzxlyWFPpQPt2rVL3t7eGjRokGw2m1auXKl+/fqpTZs28vX11csvv8wrEfzMgAED9OGHH+rQoUNq3LixXnnlFb3yyivasWOHpk6dqq+++kodO3Z0qUPfO3fu1ObNm1WtWjW9+OKL2rFjh/7+97+rUqVK8vDwUIcOHVw6KC9duqS1a9cqPDxczz//vO6//36FhYUpMjJSAwcO1Pbt2+Xt7W31mJb57rvv7LcJys7Otv+/8fDw0JkzZ3T48GGXDsqkpCTFxsbqwQcf1IoVK1SmTBnt27dPW7du1aOPPqrly5dbPaLl8n9Z69Kli4KDg7V06VL7S8GuW7eOu5b8j/zD2RMmTLC/StV9992nY8eOadeuXWrTpo0kuczPMfZUOlBMTIzKly+viRMn6osvvtDcuXPVrFkzxcTEaNSoUfLx8dHrr79u9ZhO4aefftI333yjoKAgNW3aVDVq1NADDzxgP3zwc/m/Of/W7dq1S88++6yuXr2qUqVKqV27dvrb3/6mEydO6K233lKTJk0UGRnp8vc3zX+lildffVVnz55Vbm6uGjVqpO7du6tt27ZWj2epK1euqEePHnr22WdvOO/tL3/5i86ePevSt6IaM2aMqlWrphdeeEEvv/yyVq1apREjRkiSEhIS9NZbb6l+/foWT2md/DuX7N27V6dOnVL37t118uRJPffcc/L29tbWrVu1fv16do4U4vDhw3rnnXd05coVjRkzRo0aNbJ6JEv89rO5BDVr1kwnTpzQ+fPnNWnSJNWsWVN9+/aVh4eH/Pz8lJmZafWITuP3v/+9mjdvrrJly+rjjz/WgAEDtGfPHvXu3Vvh4eEF9hi4QlBK0rx589SzZ0/t3LlTCQkJOnnypPr166fWrVvr9OnT+sc//uHyQbl48WK9++67WrJkid544w2NGDFCjzzyiMqWLauXX35ZsbGxVo9oqTJlyigiIkKDBg1Snz59tGjRIp0+fVpTpkzR6tWrFRkZafWIltq0aZN69eol6foLVEyZMkVRUVGKioqSt7e3Sx2mLIyn5/WDl9OnT9fZs2clSX5+fvrDH/6gzp07a9WqVQTlz+Tl5UmSMjIyVKNGDb311lsqX768unbtqrfeesu+DV0Jh78d6IEHHtD8+fPVrFkz1ahRQ+PGjbPfXHj16tWaMWOGxRM6n3feeUejR49Wo0aN1LNnT504cUKffPKJ/ZCCqxwykKSvvvpKK1eulCRVqlRJp0+fVvPmzfXpp5+qbt26Ln8bqqSkJE2ZMkVdunS54dBl+/btNXr06N/sq1T8EqNHj1bbtm0VHx+vt99+WyNHjlS3bt00ZcoUNW3a1OrxLLNz507t3r1b8+bNU/369XX+/PkCt+ZKS0vTiy++aOGE1jp37pz279+vTp06qXLlyvZ4vOuuu7gF1U3k/2x6/PHHlZmZqcaNG6tr1646evSoxo0bp7p167rcRU1EpQNVrlxZn3/+uc6ePStPT0+VK1dOV65c0fLly3Xt2jWFhIRYPaJTOX78uP71r39pzJgxysvLU8WKFVWxYkX5+/urSpUqklzjajnpvz/w3n33Xfvre2dnZys2Ntblr9TNFx8frwEDBtgPXf7zn//UiBEj1LhxY33++edq3LixAgMDrR7TKbRq1UpNmjRRbm6url27plKlSqls2bIucypJYZo3b65z585pyZIlmjRpkv1UgO7duys9PV2enp4uHd2zZs1STk6OvLy89Pbbb2vTpk0qV66c6tWr5/KvLHQr33//vcqVK6d77rlHVatW1eXLlzVixAh169ZNYWFhklznFC6JcyqL3ffff681a9aoTJky/Lb3/y5fvmy/sfDw4cPVunVrPfXUUzpx4oSWLFmiU6dOueSrfVy4cEHLli3T9OnT9dNPP8nLy0urV69W2bJleTk9XY+CpUuXqlatWurSpYtiYmLse5r69OmjVq1a6fnnn7d4StwpkpOT9d5772nFihVKTU3Vyy+/rD/+8Y9Wj2WZTp066f3331etWrW0cOFCffzxx0pKSlJwcLDuv/9+DRw40P7LPm60YsUKnTp1Sm3btlWLFi0kudaRtnxEJUpUenq6ZsyYoU6dOqlBgwZKTEzUihUrVLFiRW3ZskVhYWF64oknFBIS4hI3ir2Z1NRUzZo1S0uWLJG3t7dmzZrl0nu6d+7cqZYtW2rixImqX7++3nrrLSUlJdk/36FDB02fPt2l9zTh18nLy9O+fftUs2ZNl/3lbdeuXWrXrp3Wr19vv1pZks6ePasFCxbo3Xff1Zw5c9ShQwcLp3Q+165d0+jRo/Xggw8qLy9PCxYs0Lp169SjRw/Fxsa6ZIQTlShRe/fu1R//+EddvnxZgYGBCggI0IoVK9SgQQP99a9/VY0aNawe0ank5eUpMTFRwcHBLn9O5YULF7RkyRL985//1NmzZzV+/Hj7ocuJEydq/fr1Vo8I3JGee+45rVmzRtnZ2crKylJERISefvppNW7c2OrRnNqpU6f0yiuv6PTp06pdu7bKly+vTz/9VFeuXNE333zjcnspJaISFklOTtby5cv19ddf6+TJk2rZsqVat26t8PBwwhK3xaFLwHHatGmjzz77TBUqVFBCQoLmz5+vDRs2yM/PT927d9fLL7+s3//+9y4ZSUWVnZ0tDw8Pubu76/Tp06patSqHv4HitGfPHsXGxuqpp55Sx44d7Ye29+zZoxUrVmjVqlWaO3cuV/CiyDh0CZjZvHmzxo0bp6+//rpABJ07d04JCQmaMWOGPvzwQ/Za/r/8i24yMzP1/vvvKzExUZ6enmrYsKEGDBjg8i8TS1SixHzzzTcaN26cjhw5ovLly6tbt27q1auXPSJd6Qo5AHAW165d01133eXS57H/Un/+85+VmJiodu3aqWrVqvriiy9Up04dTZw40erRLEVUosTl5OQoPj5e8fHx+vbbb9WgQQOFhYVp2LBhLn/eIADAeR07dky1a9dWeHi4FixYoGrVqunq1avatWuXxo4dqzfffFPt2rWzekzLuNbBflgqNzdXNptNnp6eGjx4sL744gtt3brVfiuLCxcuWD0iAACF2rRpk6KiojR58mTVrFlTq1evVlZWlkqXLq22bdvq4sWL8vHxkXT9yJsrYk8lSkT+uTrHjx/X4sWLdf78eQ0YMEDNmjWzejQAAG4rMzNTCxYs0JYtW3Tw4EHZbDY988wz8vT0VHp6unbt2qWlS5e69KlcRCVKVNOmTfX0009rxIgRkqTatWurR48eevXVV+Xt7e2y/xEBAHeOtLQ0ffzxx1q9erXS0tJ05coVzZ07V6GhoS551Xc+1/yqUaKuXbsmSfr0009Vv359PfLIIwoLC9O1a9cUEBCg+Ph4ZWdnE5QAAKeUl5cnSTpw4ICWL1+usmXLauTIkVq1apXmz5+v3r1726+Qd9WglHjtb5SAd955R48++qh27NihyMhILVy4UMHBwXJ3d9egQYPk6ekpHx8flz5kAABwXvmhuGXLFr311luqXbu2Wrdura5du6pFixaaNGmSxRM6B9fNaZSIrKwsJSUl6amnnlJaWppatGihypUrq0KFCpKkDz74QNnZ2RZPCQDA7UVFRenAgQN66qmn9M0336hLly564IEHdOLECatHcwqcU4li9+OPP+qf//yn5s6dqzZt2ig8PFxjxoxRbm6u2rdvr5UrV7r04QIAgPPKP0cyLy9Pbm5uBY6offjhh1q2bJkSEhI40ib2VKKY2Ww2lS1bVmPHjtUnn3wib29v7du3T19//bWOHj2qRYsWyd3d3WVvvwAAcG75Oz3+/Oc/a8mSJTpz5oyuXLki6frPuLZt28rNzc1+3qUr45xKFJsjR45o7dq1ysnJ0e9+9zt1795dERERev311/X222/r2Wef1RtvvCFJ/IYHAHA6GRkZcnd3l4+Pj86ePaslS5bI3d1dDz/8sGrWrKnJkydrzpw5Vo/pNDj8jWLz5z//WX/60580atQoXbt2TTt37lSnTp1Urlw5zZgxQ+7u7kpLS7N6TAAACjV06FD5+Pho8uTJ8vDwkM1m0/z58/XBBx8oICBADz74oPr162f1mE6DqESxuXTpkmbPnq29e/dq2LBh6tChg1JTU2Wz2eTl5aX09HQ1aNBAOTk58vRkpzkAwLmEhIToyy+/lK+vr06dOqWBAweqfPnyqlevnp5++mn5+/tbPaJT4ZxKFJty5cpp9OjR6tGjhyZOnKghQ4bou+++U0BAgCpUqKAGDRpIEkEJAHA6H330kQICAuTr66vTp0/rzTffVNmyZTVw4EAlJSXpgw8+UG5urtVjOhV+mqNYbNq0SRUqVFCjRo3Up08fhYeHa/369Vq/fr2ys7PVtm1bq0cEAOCmfvrpJ9WvX1+SNH/+fJ0+fVrjxo1T+/btVb58eb399tvy8PCweErnwuFvONxPP/2kwYMHa//+/Tp37pzuv/9+lStXTgcPHtSePXt0+fJlLV++XI8++qjVowIAUKiUlBSFh4fLw8NDP/zwg+Li4tS9e3d5eHgoKipKjRo10qhRo5Sbm0tc/j+iEg5ns9mUlpYmb29vHT16VElJSfLw8JCHh4d2796t1NRUzZs3T+XKleNVdAAATuvSpUv68ssvVa5cOT3wwAOSpFOnTun+++/X5s2bVbFiRYsndC5EJQAAQBH88MMPWrp0qfbu3atp06bZb4yO64hKlCj+AwIA7lQ2m01Xr15Vbm6uypYty9G2/0FUAgAAwBi7jAAAAGCMqAQAAIAxohIAAADGiEoAAAAYIyoBAABgjKgEAACAsf8DC3zpffDQsx0AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 10), dpi=80)\n",
        "\n",
        "# unique, counts = np.unique(labels, return_counts=True)\n",
        "# plt.bar(CLASS_LABELS[unique], counts)\n",
        "# plt.xticks(rotation=70)\n",
        "\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(counts)\n",
        "print(type(unique[0]))\n",
        "plt.bar(CLASS_LABELS[unique], counts)\n",
        "plt.xticks(rotation=70)\n",
        "\n",
        "# unique, counts = np.unique(y_test, return_counts=True)\n",
        "# plt.bar(CLASS_LABELS[unique], counts)\n",
        "# plt.xticks(rotation=70)\n",
        "\n",
        "unique, counts = np.unique(y_val, return_counts=True)\n",
        "print(counts)\n",
        "plt.bar(CLASS_LABELS[unique], counts)\n",
        "plt.xticks(rotation=70)\n",
        "\n",
        "# plt.legend([\"All\", \"Train\", \"Test\", \"Validation\"])\n",
        "plt.legend([\"Train\", \"Validation\"])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_arrays(x, y, batch_size=32):\n",
        "    i = 0\n",
        "    while True:\n",
        "        batch_X = x[i * batch_size : (i + 1) * batch_size]\n",
        "        batch_y = y[i * batch_size : (i + 1) * batch_size]\n",
        "        if (i + 1) * batch_size >= len(x):\n",
        "            i = 0 # iのリセットは必要\n",
        "        else:\n",
        "            i += 1\n",
        "        yield process_data(batch_X, batch_y)\n",
        "        \n",
        "        \n",
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, x_set, y_set, batch_size):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        return batch_x, batch_y\n",
        "    \n",
        "def process_data(batch_X, batch_y):\n",
        "    # arr = {}   \n",
        "    # # パディングして履歴の長さをそろえる\n",
        "    # for c in batch_df.columns:\n",
        "    #     arr[c] = pad_sequences(batch_df[c], dtype='float32', maxlen=MAX_RES_TOKENS)\n",
        "\n",
        "    return (batch_X, batch_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QaZxGMgKZznS"
      },
      "outputs": [],
      "source": [
        "def train(config=None):\n",
        "  # with wandb.init(config=config):\n",
        "  #   config = wandb.config\n",
        "    # Generate new model  \n",
        "    model = Transformer(\n",
        "      num_layers=config.num_layers,\n",
        "      embed_dim=config.embed_layer_size,\n",
        "      mlp_dim=config.fc_layer_size,\n",
        "      num_heads=config.num_heads,\n",
        "      num_classes=8,\n",
        "      dropout_rate=config.dropout,\n",
        "      attention_dropout_rate=config.attention_dropout,\n",
        "    )\n",
        "    generator_train = DataGenerator(X_train,y_train,batch_size=config.batch_size)\n",
        "    generator_val = DataGenerator(X_val,y_val,batch_size=config.batch_size)\n",
        "    checkpoint_path = os.path.join(OUTPUT_DIR,MODEL_OUT,\"cp-{epoch:04d}.ckpt\")\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "    # adapt on training dataset - must be before model.compile !!!\n",
        "    model.input_norm.adapt(X_train, batch_size=config.batch_size)\n",
        "    print(model.input_norm.variables)\n",
        "\n",
        "    # Select optimizer\n",
        "    if config.optimizer == \"adam\":\n",
        "      optim = Adam(\n",
        "          global_clipnorm=config.global_clipnorm,\n",
        "          amsgrad=config.amsgrad,\n",
        "      )\n",
        "    elif config.optimizer == \"adamw\":\n",
        "      optim = AdamW(\n",
        "          weight_decay=config.weight_decay,\n",
        "          amsgrad=config.amsgrad,\n",
        "          global_clipnorm=config.global_clipnorm,\n",
        "          exclude_from_weight_decay=[\"position\"]\n",
        "      )\n",
        "    else:\n",
        "      raise ValueError(\"The used optimizer is not in list of available\")\n",
        "\n",
        "    model.compile(\n",
        "      loss=smoothed_sparse_categorical_crossentropy(label_smoothing=config.label_smoothing),\n",
        "      optimizer=optim,\n",
        "      metrics=[\"accuracy\"],\n",
        "    )\n",
        "    model.build(input_shape=(config.batch_size,500,9))\n",
        "    # model.load_weights(os.path.join(OUTPUT_DIR,'0531.data-00000-of-00001'))\n",
        "    # Train model\n",
        "    \n",
        "      # model.fit(\n",
        "      #   X_train,\n",
        "      #   y_train,\n",
        "      #   batch_size=config.batch_size,\n",
        "      #   epochs=config.epochs,\n",
        "      #   validation_data=(X_val, y_val),\n",
        "      #   steps_per_epoch=config.steps_per_epoch\n",
        "      #   callbacks=[\n",
        "      #     LearningRateScheduler(cosine_schedule(base_lr=config.learning_rate, total_steps=config.epochs, warmup_steps=config.warmup_steps)),\n",
        "      #     # PrintLR(),\n",
        "      #     ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1),\n",
        "      #     # WandbCallback(monitor=\"val_accuracy\", mode='max', save_weights_only=True),\n",
        "      #     EarlyStopping(monitor=\"val_accuracy\", mode='max', min_delta=0.001, patience=5),\n",
        "      #   ],\n",
        "      #   verbose=1\n",
        "      # )\n",
        "      # 一度にメモリに乗せるデータ\n",
        "      model.fit(\n",
        "          generator_train,\n",
        "          validation_data=generator_val,\n",
        "          epochs=config.epochs,\n",
        "          steps_per_epoch=len(X_train) // config.batch_size,\n",
        "          validation_steps=len(X_val) // config.batch_size,\n",
        "          callbacks=[\n",
        "          LearningRateScheduler(cosine_schedule(base_lr=config.learning_rate, total_steps=config.epochs, warmup_steps=config.warmup_steps)),\n",
        "          # PrintLR(),\n",
        "          ModelCheckpoint(filepath=checkpoint_path,save_weights_only=True,verbose=1),\n",
        "          # WandbCallback(monitor=\"val_accuracy\", mode='max', save_weights_only=True),\n",
        "          EarlyStopping(monitor=\"val_accuracy\", mode='max', min_delta=0.001, patience=5),\n",
        "        ],\n",
        "        verbose=1\n",
        "      )\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "      del model\n",
        "  \n",
        "    # plot_model(\n",
        "    # model,\n",
        "    # show_shapes=True,\n",
        "    # )\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class config:\n",
        "  epochs=50\n",
        "  num_layers=3\n",
        "  # embed_layer_size=96\n",
        "  embed_layer_size=128\n",
        "  fc_layer_size=256\n",
        "  # num_heads=6\n",
        "  num_heads=6\n",
        "  dropout=0.2\n",
        "  attention_dropout=0.2\n",
        "  optimizer='adamw'\n",
        "  amsgrad=False\n",
        "  label_smoothing=0.1\n",
        "  learning_rate=1e-4\n",
        "  weight_decay=5e-5\n",
        "  warmup_steps=10\n",
        "  batch_size=32\n",
        "  global_clipnorm=3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c2f96abecad54565be62d18c1b5c1e68",
            "fa0aba1429524429af176534638122db",
            "0054c6582b4c45faa323add90dd34770",
            "634c65b48e0b40359f6158364fb54ad7",
            "ebdfa2b37e5540e39bd6624f22eeb19a",
            "7198820fcadc4aaf875ee617dd605fbc",
            "18adf181e391491a9426d17e69a8c574",
            "dc1f7e46eaf643999d482c3b17e3bee6"
          ]
        },
        "id": "J743-OTSSsZy",
        "outputId": "1ea18bc2-7308-4e10-cabf-7c94643fab4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<tf.Variable 'mean:0' shape=(9,) dtype=float32, numpy=\n",
            "array([-8.7519389e-01, -6.0505122e-02, -4.0406590e+00,  3.0122532e-03,\n",
            "       -8.3216961e-04, -4.0412671e-03,  1.5119601e+00, -3.8158035e-01,\n",
            "        1.0203282e+01], dtype=float32)>, <tf.Variable 'variance:0' shape=(9,) dtype=float32, numpy=\n",
            "array([3.60271568e+01, 3.05202122e+01, 4.26727791e+01, 1.23518777e+00,\n",
            "       1.24649918e+00, 8.31556261e-01, 1.01520715e+03, 1.05609973e+03,\n",
            "       1.22910986e+03], dtype=float32)>, <tf.Variable 'count:0' shape=() dtype=int64, numpy=95018500>]\n",
            "Epoch 1/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.9369 - accuracy: 0.2962\n",
            "Epoch 1: saving model to ../output/model/transformer/0606\\cp-0001.ckpt\n",
            "5938/5938 [==============================] - 991s 166ms/step - loss: 1.9369 - accuracy: 0.2962 - val_loss: 1.9348 - val_accuracy: 0.0851 - lr: 1.0000e-05\n",
            "Epoch 2/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.7210 - accuracy: 0.3507\n",
            "Epoch 2: saving model to ../output/model/transformer/0606\\cp-0002.ckpt\n",
            "5938/5938 [==============================] - 990s 167ms/step - loss: 1.7210 - accuracy: 0.3507 - val_loss: 1.8241 - val_accuracy: 0.2116 - lr: 2.0000e-05\n",
            "Epoch 3/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.6410 - accuracy: 0.3809\n",
            "Epoch 3: saving model to ../output/model/transformer/0606\\cp-0003.ckpt\n",
            "5938/5938 [==============================] - 998s 168ms/step - loss: 1.6410 - accuracy: 0.3809 - val_loss: 1.7700 - val_accuracy: 0.2767 - lr: 3.0000e-05\n",
            "Epoch 4/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.5969 - accuracy: 0.4063\n",
            "Epoch 4: saving model to ../output/model/transformer/0606\\cp-0004.ckpt\n",
            "5938/5938 [==============================] - 1052s 177ms/step - loss: 1.5969 - accuracy: 0.4063 - val_loss: 1.8155 - val_accuracy: 0.3225 - lr: 4.0000e-05\n",
            "Epoch 5/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.5679 - accuracy: 0.4364\n",
            "Epoch 5: saving model to ../output/model/transformer/0606\\cp-0005.ckpt\n",
            "5938/5938 [==============================] - 673s 113ms/step - loss: 1.5679 - accuracy: 0.4364 - val_loss: 1.7873 - val_accuracy: 0.3664 - lr: 5.0000e-05\n",
            "Epoch 6/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.5319 - accuracy: 0.4648\n",
            "Epoch 6: saving model to ../output/model/transformer/0606\\cp-0006.ckpt\n",
            "5938/5938 [==============================] - 982s 165ms/step - loss: 1.5319 - accuracy: 0.4648 - val_loss: 1.8399 - val_accuracy: 0.3202 - lr: 6.0000e-05\n",
            "Epoch 7/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.5152 - accuracy: 0.4726\n",
            "Epoch 7: saving model to ../output/model/transformer/0606\\cp-0007.ckpt\n",
            "5938/5938 [==============================] - 957s 161ms/step - loss: 1.5152 - accuracy: 0.4726 - val_loss: 1.8281 - val_accuracy: 0.2436 - lr: 7.0000e-05\n",
            "Epoch 8/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4916 - accuracy: 0.4813\n",
            "Epoch 8: saving model to ../output/model/transformer/0606\\cp-0008.ckpt\n",
            "5938/5938 [==============================] - 950s 160ms/step - loss: 1.4916 - accuracy: 0.4813 - val_loss: 1.8351 - val_accuracy: 0.3952 - lr: 8.0000e-05\n",
            "Epoch 9/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4786 - accuracy: 0.4934\n",
            "Epoch 9: saving model to ../output/model/transformer/0606\\cp-0009.ckpt\n",
            "5938/5938 [==============================] - 941s 159ms/step - loss: 1.4786 - accuracy: 0.4934 - val_loss: 1.6775 - val_accuracy: 0.4286 - lr: 9.0000e-05\n",
            "Epoch 10/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4608 - accuracy: 0.5043\n",
            "Epoch 10: saving model to ../output/model/transformer/0606\\cp-0010.ckpt\n",
            "5938/5938 [==============================] - 945s 159ms/step - loss: 1.4608 - accuracy: 0.5043 - val_loss: 1.8073 - val_accuracy: 0.4134 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4490 - accuracy: 0.5059\n",
            "Epoch 11: saving model to ../output/model/transformer/0606\\cp-0011.ckpt\n",
            "5938/5938 [==============================] - 955s 161ms/step - loss: 1.4490 - accuracy: 0.5059 - val_loss: 1.7622 - val_accuracy: 0.3449 - lr: 9.9846e-05\n",
            "Epoch 12/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4374 - accuracy: 0.5123\n",
            "Epoch 12: saving model to ../output/model/transformer/0606\\cp-0012.ckpt\n",
            "5938/5938 [==============================] - 953s 160ms/step - loss: 1.4374 - accuracy: 0.5123 - val_loss: 1.8322 - val_accuracy: 0.3486 - lr: 9.9384e-05\n",
            "Epoch 13/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4300 - accuracy: 0.5143\n",
            "Epoch 13: saving model to ../output/model/transformer/0606\\cp-0013.ckpt\n",
            "5938/5938 [==============================] - 949s 160ms/step - loss: 1.4300 - accuracy: 0.5143 - val_loss: 1.8554 - val_accuracy: 0.4362 - lr: 9.8618e-05\n",
            "Epoch 14/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4311 - accuracy: 0.5221\n",
            "Epoch 14: saving model to ../output/model/transformer/0606\\cp-0014.ckpt\n",
            "5938/5938 [==============================] - 935s 157ms/step - loss: 1.4311 - accuracy: 0.5221 - val_loss: 1.7116 - val_accuracy: 0.4310 - lr: 9.7553e-05\n",
            "Epoch 15/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4210 - accuracy: 0.5274\n",
            "Epoch 15: saving model to ../output/model/transformer/0606\\cp-0015.ckpt\n",
            "5938/5938 [==============================] - 942s 159ms/step - loss: 1.4210 - accuracy: 0.5274 - val_loss: 1.6397 - val_accuracy: 0.3813 - lr: 9.6194e-05\n",
            "Epoch 16/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4219 - accuracy: 0.5244\n",
            "Epoch 16: saving model to ../output/model/transformer/0606\\cp-0016.ckpt\n",
            "5938/5938 [==============================] - 938s 158ms/step - loss: 1.4219 - accuracy: 0.5244 - val_loss: 1.6368 - val_accuracy: 0.4676 - lr: 9.4550e-05\n",
            "Epoch 17/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4160 - accuracy: 0.5267\n",
            "Epoch 17: saving model to ../output/model/transformer/0606\\cp-0017.ckpt\n",
            "5938/5938 [==============================] - 922s 155ms/step - loss: 1.4160 - accuracy: 0.5267 - val_loss: 1.6401 - val_accuracy: 0.4660 - lr: 9.2632e-05\n",
            "Epoch 18/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4101 - accuracy: 0.5311\n",
            "Epoch 18: saving model to ../output/model/transformer/0606\\cp-0018.ckpt\n",
            "5938/5938 [==============================] - 910s 153ms/step - loss: 1.4101 - accuracy: 0.5311 - val_loss: 1.6243 - val_accuracy: 0.3711 - lr: 9.0451e-05\n",
            "Epoch 19/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4119 - accuracy: 0.5276\n",
            "Epoch 19: saving model to ../output/model/transformer/0606\\cp-0019.ckpt\n",
            "5938/5938 [==============================] - 910s 153ms/step - loss: 1.4119 - accuracy: 0.5276 - val_loss: 1.6626 - val_accuracy: 0.4170 - lr: 8.8020e-05\n",
            "Epoch 20/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4137 - accuracy: 0.5282\n",
            "Epoch 20: saving model to ../output/model/transformer/0606\\cp-0020.ckpt\n",
            "5938/5938 [==============================] - 910s 153ms/step - loss: 1.4137 - accuracy: 0.5282 - val_loss: 1.7387 - val_accuracy: 0.4345 - lr: 8.5355e-05\n",
            "Epoch 21/50\n",
            "5938/5938 [==============================] - ETA: 0s - loss: 1.4098 - accuracy: 0.5317\n",
            "Epoch 21: saving model to ../output/model/transformer/0606\\cp-0021.ckpt\n",
            "5938/5938 [==============================] - 910s 153ms/step - loss: 1.4098 - accuracy: 0.5317 - val_loss: 1.7658 - val_accuracy: 0.3306 - lr: 8.2472e-05\n",
            "Model: \"transformer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " normalization (Normalizatio  multiple                 19        \n",
            " n)                                                              \n",
            "                                                                 \n",
            " positional_embedding (Posit  multiple                 65280     \n",
            " ionalEmbedding)                                                 \n",
            "                                                                 \n",
            " encoder (Encoder)           multiple                  462080    \n",
            "                                                                 \n",
            " encoder_1 (Encoder)         multiple                  462080    \n",
            "                                                                 \n",
            " encoder_2 (Encoder)         multiple                  462080    \n",
            "                                                                 \n",
            " layer_normalization_6 (Laye  multiple                 256       \n",
            " rNormalization)                                                 \n",
            "                                                                 \n",
            " dense_7 (Dense)             multiple                  1032      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,452,827\n",
            "Trainable params: 1,452,808\n",
            "Non-trainable params: 19\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "train(config=config)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model: \"transformer\"\n",
        "_________________________________________________________________\n",
        " Layer (type)                Output Shape              Param    \n",
        "=================================================================\n",
        " normalization (Normalizatio  multiple                 19        n)                                                              \n",
        "                                                                 \n",
        " positional_embedding (Posit  multiple                 65280     \n",
        " ionalEmbedding)                                                 \n",
        "                                                                 \n",
        " encoder (Encoder)           multiple                  396160    \n",
        "                                                                 \n",
        " encoder_1 (Encoder)         multiple                  396160    \n",
        "                                                                 \n",
        " encoder_2 (Encoder)         multiple                  396160    \n",
        "                                                                 \n",
        " layer_normalization_6 (Laye  multiple                 256       \n",
        " rNormalization)                                                 \n",
        "                                                                 \n",
        " dense_7 (Dense)             multiple                  2322      \n",
        "                                                                 \n",
        "=================================================================\n",
        "Total params: 1,256,357\n",
        "Trainable params: 1,256,338\n",
        "Non-trainable params: 19\n",
        "_________________________________________________________________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "config.num_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "'type' object is not iterable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m process_eval \u001b[39m=\u001b[39m multiprocessing\u001b[39m.\u001b[39;49mProcess(target\u001b[39m=\u001b[39;49mtrain, args\u001b[39m=\u001b[39;49m(config))\n\u001b[0;32m      4\u001b[0m process_eval\u001b[39m.\u001b[39mstart()\n\u001b[0;32m      5\u001b[0m process_eval\u001b[39m.\u001b[39mjoin()\n",
            "File \u001b[1;32mc:\\Users\\bsa\\Anaconda3\\envs\\shl2023\\lib\\multiprocessing\\process.py:91\u001b[0m, in \u001b[0;36mBaseProcess.__init__\u001b[1;34m(self, group, target, name, args, kwargs, daemon)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_closed \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target \u001b[39m=\u001b[39m target\n\u001b[1;32m---> 91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(args)\n\u001b[0;32m     92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(kwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \\\n\u001b[0;32m     94\u001b[0m              \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_identity)\n",
            "\u001b[1;31mTypeError\u001b[0m: 'type' object is not iterable"
          ]
        }
      ],
      "source": [
        "import multiprocessing\n",
        "\n",
        "process_eval = multiprocessing.Process(target=train, args=(config))\n",
        "process_eval.start()\n",
        "process_eval.join()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Training_posledna_verzia_3-3.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "9185113d2128201d66faecd4f34fb34e89a635073a034991399523e584519355"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0054c6582b4c45faa323add90dd34770": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7198820fcadc4aaf875ee617dd605fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_ebdfa2b37e5540e39bd6624f22eeb19a",
            "value": " 5.55MB of 5.55MB uploaded (0.00MB deduped)\r"
          }
        },
        "18adf181e391491a9426d17e69a8c574": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "634c65b48e0b40359f6158364fb54ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc1f7e46eaf643999d482c3b17e3bee6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18adf181e391491a9426d17e69a8c574",
            "value": 1
          }
        },
        "7198820fcadc4aaf875ee617dd605fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f96abecad54565be62d18c1b5c1e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0054c6582b4c45faa323add90dd34770",
              "IPY_MODEL_634c65b48e0b40359f6158364fb54ad7"
            ],
            "layout": "IPY_MODEL_fa0aba1429524429af176534638122db"
          }
        },
        "dc1f7e46eaf643999d482c3b17e3bee6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebdfa2b37e5540e39bd6624f22eeb19a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa0aba1429524429af176534638122db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
